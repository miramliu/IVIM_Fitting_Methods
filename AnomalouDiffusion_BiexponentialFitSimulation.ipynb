{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06ebd62",
   "metadata": {},
   "source": [
    "# 2/2/2025\n",
    "\n",
    "Brain perfusion, bi-exponential anomalous diffusion fit with four different methods\n",
    "\n",
    "\n",
    "Code is not neatened up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82b70135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import scipy.optimize as op\n",
    "import scipy.stats\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.io\n",
    "from scipy.stats import rice\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, ttest_ind_from_stats, wilcoxon,ttest_rel, pearsonr,shapiro,f_oneway, ranksums\n",
    "from scipy.special import stdtr\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.integrate import quad\n",
    "import sys \n",
    "import os\n",
    "#sys.path.append(os.path.abspath(\"/Users/neuroimaging/Desktop/MR-code/Python_Code\"))\n",
    "\n",
    "#from ML_UsefulFunctions import *\n",
    "#from KidneyROIAnalyses import *\n",
    "\n",
    "from scipy import special\n",
    "\n",
    "from scipy.integrate import tplquad\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "from EllipsoidalSimulationCode import *\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "def func(x,m,b):\n",
    "    return m*x + b\n",
    "\n",
    "def triexp_func(b, frac_fast,frac_med,frac_slow,diff_fast,diff_med,diff_slow):\n",
    "    Data = frac_slow*np.exp(-b*diff_slow)+frac_med*np.exp(-b*diff_med)+frac_fast*np.exp(-b*diff_fast)\n",
    "    normal = frac_slow+frac_med+frac_fast\n",
    "    return Data/normal\n",
    "\n",
    "\n",
    "## note here that diff_slow should be diff**gamma. instead it isn't. so it's slightly different. \n",
    "\n",
    "def anomalous_triexp_func(b, frac_fast,frac_med,frac_slow,diff_fast,diff_med,diff_slow, gamma_fast, gamma_med, gamma_slow):\n",
    "    Data = frac_slow*np.exp(-(b*diff_slow)**gamma_slow)+frac_med*np.exp(-(b*diff_med)**gamma_med)+frac_fast*np.exp(-(b*diff_fast)**gamma_fast)\n",
    "    normal = frac_slow+frac_med+frac_fast\n",
    "    return Data/normal\n",
    "\n",
    "def CalculatePE_fraction(df, trait):\n",
    "    df[trait + ' PE'] = (df['Fit ' + trait]-df['true ' + trait])#*100/(df['true ' + trait])\n",
    "    return df\n",
    "\n",
    "def CalculatePE_diffusion(df, trait): #scale by 1000\n",
    "    df[trait + ' PE'] = ((df['Fit ' +trait]/1000)-df['true ' + trait])#*100/(df['true ' + trait])\n",
    "    return df\n",
    "\n",
    "def blandalt_calc(FitfDs,TruefDs, name):\n",
    "    mean_diff = np.mean(FitfDs-TruefDs)\n",
    "    mean_diff_percent = 100*mean_diff/np.mean((FitfDs+TruefDs)/2)\n",
    "    std_diff = np.std(FitfDs-TruefDs)\n",
    "    std_diff_percent = 100*std_diff/np.mean((FitfDs+TruefDs)/2)\n",
    "    lower_bound=mean_diff-(std_diff*1.96)\n",
    "    upper_bound=mean_diff+(std_diff*1.96)\n",
    "    lower_bound_percent=mean_diff_percent-(1.96*std_diff_percent)\n",
    "    upper_bound_percent=mean_diff_percent+(1.96*std_diff_percent)\n",
    "    print(f'{name} BA, {mean_diff:.3f}, [{lower_bound:.3f}-{upper_bound:.3f}]')\n",
    "    print(f'{name} %BA, {mean_diff_percent:.3f}%, [{lower_bound_percent:.3f}%-{upper_bound_percent:.3f}%]\\n')\n",
    "    return\n",
    "    \n",
    "def func(x,m,b):\n",
    "    return m*x + b\n",
    "\n",
    "\n",
    "def biexp_func(b, frac_fast,frac_slow,diff_fast,diff_slow):\n",
    "    Data = frac_slow*np.exp(-b*diff_slow)+frac_fast*np.exp(-b*diff_fast)\n",
    "    normal = frac_slow+frac_fast\n",
    "    return Data/normal\n",
    "\n",
    "def monoexp_func(b, frac, diff):\n",
    "    Data = frac*np.exp(-b*diff)\n",
    "    return Data\n",
    "\n",
    "#Rician noise check\n",
    "\n",
    "#SNR = 1, sigma = 1\n",
    "#SNR = 10, sigma = .1\n",
    "#SNR = 20, sigma = .045\n",
    "#SNR = 50, sigma = .02\n",
    "#SNR = 75, sigma = .013\n",
    "#SNR = 100, sigma = .01\n",
    "#SNR = 125, sigma = .008\n",
    "#SNR = 150, sigma = .0065\n",
    "def NoiseRice(I,SNR): # noise with rician distribution\n",
    "    N = [] \n",
    "    sigma = 1/SNR\n",
    "    #v = .79 # calculated from images on 6/11/19\n",
    "    #sigma = .013 #(std of noise measured!)\n",
    "    #v = 0.00434 #scaled = .79/182\n",
    "    v = .005816 #scaled 6/27/19\n",
    "    b = v/sigma\n",
    "    r = rice.rvs(b, scale = sigma, size=len(I))\n",
    "    for i in range(0,len(I)):\n",
    "        N.append(I[i] +r[i]) #SNR = 1,10,22,100,150,inf\n",
    "    return N\n",
    "\n",
    "\n",
    "def ExportToDF(df, IdentifyingInfo, data):\n",
    "    if isinstance(data, list):\n",
    "        Export = data\n",
    "        Export.insert(0, IdentifyingInfo)\n",
    "        df.loc[ len(df),: ] = Export\n",
    "    else:\n",
    "        Export = data.tolist()\n",
    "        Export.insert(0, IdentifyingInfo)\n",
    "        df.loc[ len(df),: ] = Export\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779acd5c",
   "metadata": {},
   "source": [
    "# simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a2956",
   "metadata": {},
   "source": [
    "# Generate N 2 compartment voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "615f4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Completed in  67.40425491333008\n"
     ]
    }
   ],
   "source": [
    "# Run it n times... get n 'voxels'\n",
    "n = 1000\n",
    "#set up with given b-values\n",
    "b_values=np.array([0,50,100,150,200,250,300,500,700,900])\n",
    "#anisotropies\n",
    "fastFA = np.abs(np.random.normal(0.09, .04,n))\n",
    "medFA = np.zeros(n) # set to zero for bi-exponential\n",
    "slowFA = np.abs(np.random.normal(0.18, 0.1,n))\n",
    "\n",
    "#diffusion coefficients \n",
    "#D_traces = [0.180, 0.0058, 0.0015] #true D coefficients\n",
    "fastD = np.abs(np.random.normal(0.07, 0.009,n))\n",
    "medD = np.zeros(n) # set to zero for bi-exponential\n",
    "slowD = np.abs(np.random.normal(0.001, 0.00075,n))\n",
    "\n",
    "\n",
    "# fractions\n",
    "fastfracs = np.abs(np.random.normal(.07, 0.07,n))\n",
    "medfracs = np.zeros(n) # set to zero for bi-exponential\n",
    "slowfracs = 1-fastfracs\n",
    "\n",
    "\n",
    "#anomalous diffusion coefficients\n",
    "gamma_fast =  np.abs(np.random.normal(1.75, 0.2,n))\n",
    "gamma_med = np.abs(np.random.normal(1, 0.1,n)) #Gamma is one, but doesn't matter\n",
    "gamma_slow =  np.abs(np.random.normal(.85, 0.05,n))\n",
    "\n",
    "df_True = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])\n",
    "df_TrueNoise = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_AveragedNoise = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_True_anomalous = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_TrueNoise_anomalous = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_AveragedNoise_anomalous = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "\n",
    "df_True_SNR50 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_TrueNoise_SNR50 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_AveragedNoise_SNR50 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_True_anomalous_SNR50 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_TrueNoise_anomalous_SNR50 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_AveragedNoise_anomalous_SNR50 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "\n",
    "\n",
    "df_True_SNR30 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_TrueNoise_SNR30 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_AveragedNoise_SNR30 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_True_anomalous_SNR30 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_TrueNoise_anomalous_SNR30 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "df_AveragedNoise_anomalous_SNR30 = pd.DataFrame(columns=['Run Number','b0','b50','b100','b150','b200','b250','b300','b500','b700','b900'])#,'b1100','b1380'])\n",
    "\n",
    "print ('Running...')\n",
    "t = time.time()\n",
    "df_TrueParams = pd.DataFrame(columns = ['Run Number', 'fast frac', 'med frac', 'slow frac', 'fast Diffusion', 'med Diffusion', 'slow Diffusion', 'fast gamma', 'med gamma', 'slow gamma', 'fast FA', 'med FA', 'slow FA','Approximated fast FA', 'Approximated med FA', 'Approximated slow FA', 'fast rotx', 'fast roty', 'fast rotz','med rotx', 'med roty', 'med rotz','slow rotx', 'slow roty', 'slow rotz'])\n",
    "for j in range(n):\n",
    "    IdentifyingInfo = 'Run Number ' + str(j)\n",
    "    est_FAs = [fastFA[j], medFA[j], slowFA[j]]\n",
    "    D_traces = [fastD[j], medD[j], slowD[j]]\n",
    "    norm = fastfracs[j] + medfracs[j] + slowfracs[j]\n",
    "    f_fracs = [fastfracs[j]/norm,medfracs[j]/norm,slowfracs[j]/norm]\n",
    "    gammas = [gamma_fast[j], gamma_med[j], gamma_slow[j]]\n",
    "\n",
    "    # assume 3 random sets of orientations for fast, middle, and slow compartments\n",
    "    fast_rot = np.random.default_rng().uniform(low = 0, high = 2*np.pi, size = 3)\n",
    "    med_rot = np.random.default_rng().uniform(low = 0, high = 2*np.pi, size = 3)\n",
    "    slow_rot = np.random.default_rng().uniform(low = 0, high = 2*np.pi, size = 3)\n",
    "\n",
    "    assumed_rots = [fast_rot, med_rot, slow_rot]\n",
    "\n",
    "    # generate the 3 ellipsoids: \n",
    "    fast_compartment, med_compartment, slow_compartment, nearest_FAs = CreateThreeEllipsoidalCompartments(est_FAs,assumed_rots)\n",
    "\n",
    "    \n",
    "    #get diffusion from single direction, and averaged\n",
    "    D_single, D_averaged= GetOrthogonalD_thetas(D_traces,fast_compartment, med_compartment, slow_compartment)\n",
    "    \n",
    "    \n",
    "    # generate signals... \n",
    "    \n",
    "    \n",
    "    ### SNR = 100\n",
    "    ### first with assumed Gaussian distributions...\n",
    "    # generate the signal from 3 averaged direction\n",
    "    Est_signal_averaged = triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_averaged[0], D_averaged[1], D_averaged[2])\n",
    "    SI_est_noise_av = NoiseRice(Est_signal_averaged, 100)\n",
    "    ExportToDF(df_AveragedNoise, IdentifyingInfo, SI_est_noise_av )\n",
    "\n",
    "    # generate the signal from true trace direction\n",
    "    Est_signal_true = triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_traces[0], D_traces[1], D_traces[2])\n",
    "    ExportToDF(df_True, IdentifyingInfo, Est_signal_true )\n",
    "\n",
    "    # generate the signal from true trace direction + noise \n",
    "    SI_noise = NoiseRice(Est_signal_true, 100)\n",
    "    ExportToDF(df_TrueNoise, IdentifyingInfo, SI_noise )\n",
    "    \n",
    "    \n",
    "    ### now with the anomalous distributions... and with SNR=100\n",
    "    # generate the signal from 3 averaged direction\n",
    "    Est_signal_averaged = anomalous_triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_averaged[0], D_averaged[1], D_averaged[2],gammas[0], gammas[1], gammas[2])\n",
    "    SI_est_noise_av = NoiseRice(Est_signal_averaged, 100)\n",
    "    ExportToDF(df_AveragedNoise_anomalous, IdentifyingInfo, SI_est_noise_av )\n",
    "\n",
    "    # generate the signal from true trace direction\n",
    "    Est_signal_true = anomalous_triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_traces[0], D_traces[1], D_traces[2],gammas[0], gammas[1], gammas[2])\n",
    "    ExportToDF(df_True_anomalous, IdentifyingInfo, Est_signal_true )\n",
    "\n",
    "    # generate the signal from true trace direction + noise \n",
    "    SI_noise = NoiseRice(Est_signal_true, 100)\n",
    "    ExportToDF(df_TrueNoise_anomalous, IdentifyingInfo, SI_noise )\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### With SNR = 50\n",
    "    ### first with assumed Gaussian distributions... and with SNR = 50\n",
    "    # generate the signal from 3 averaged direction\n",
    "    Est_signal_averaged = triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_averaged[0], D_averaged[1], D_averaged[2])\n",
    "    SI_est_noise_av = NoiseRice(Est_signal_averaged, 50)\n",
    "    ExportToDF(df_AveragedNoise_SNR50, IdentifyingInfo, SI_est_noise_av)\n",
    "    #print(j,f_fracs[0],f_fracs[1],f_fracs[2], D_averaged[0], D_averaged[1], D_averaged[2])\n",
    "\n",
    "    # generate the signal from true trace direction\n",
    "    Est_signal_true = triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_traces[0], D_traces[1], D_traces[2])\n",
    "    ExportToDF(df_True_SNR50, IdentifyingInfo, Est_signal_true)\n",
    "\n",
    "    # generate the signal from true trace direction + noise \n",
    "    SI_noise = NoiseRice(Est_signal_true, 50)\n",
    "    ExportToDF(df_TrueNoise_SNR50, IdentifyingInfo, SI_noise)\n",
    "    \n",
    "\n",
    "    ### now with the anomalous distributions... and with SNR=50\n",
    "    # generate the signal from 3 averaged direction\n",
    "    Est_signal_averaged = anomalous_triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_averaged[0], D_averaged[1], D_averaged[2],gammas[0], gammas[1], gammas[2])\n",
    "    SI_est_noise_av = NoiseRice(Est_signal_averaged, 50)\n",
    "    ExportToDF(df_AveragedNoise_anomalous_SNR50, IdentifyingInfo, SI_est_noise_av )\n",
    "\n",
    "    # generate the signal from true trace direction\n",
    "    Est_signal_true = anomalous_triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_traces[0], D_traces[1], D_traces[2],gammas[0], gammas[1], gammas[2])\n",
    "    ExportToDF(df_True_anomalous_SNR50, IdentifyingInfo, Est_signal_true )\n",
    "\n",
    "    # generate the signal from true trace direction + noise \n",
    "    SI_noise = NoiseRice(Est_signal_true, 50)\n",
    "    ExportToDF(df_TrueNoise_anomalous_SNR50, IdentifyingInfo, SI_noise )\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### With SNR = 30\n",
    "    # first with assumed Gaussian distributions... and with SNR = 30\n",
    "    # generate the signal from 3 averaged direction\n",
    "    Est_signal_averaged = triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_averaged[0], D_averaged[1], D_averaged[2])\n",
    "    SI_est_noise_av = NoiseRice(Est_signal_averaged, 30)\n",
    "    ExportToDF(df_AveragedNoise_SNR30, IdentifyingInfo, SI_est_noise_av )\n",
    "\n",
    "    # generate the signal from true trace direction\n",
    "    Est_signal_true = triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_traces[0], D_traces[1], D_traces[2])\n",
    "    ExportToDF(df_True_SNR30, IdentifyingInfo, Est_signal_true )\n",
    "\n",
    "    # generate the signal from true trace direction + noise \n",
    "    SI_noise = NoiseRice(Est_signal_true, 30)\n",
    "    ExportToDF(df_TrueNoise_SNR30, IdentifyingInfo, SI_noise )\n",
    "    \n",
    "    \n",
    "    ### now with the anomalous distributions... and with SNR=30\n",
    "    # generate the signal from 3 averaged direction\n",
    "    Est_signal_averaged = anomalous_triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_averaged[0], D_averaged[1], D_averaged[2],gammas[0], gammas[1], gammas[2])\n",
    "    SI_est_noise_av = NoiseRice(Est_signal_averaged, 30)\n",
    "    ExportToDF(df_AveragedNoise_anomalous_SNR30, IdentifyingInfo, SI_est_noise_av )\n",
    "\n",
    "    # generate the signal from true trace direction\n",
    "    Est_signal_true = anomalous_triexp_func(b_values,f_fracs[0],f_fracs[1],f_fracs[2], D_traces[0], D_traces[1], D_traces[2],gammas[0], gammas[1], gammas[2])\n",
    "    ExportToDF(df_True_anomalous_SNR30, IdentifyingInfo, Est_signal_true )\n",
    "\n",
    "    # generate the signal from true trace direction + noise \n",
    "    SI_noise = NoiseRice(Est_signal_true, 30)\n",
    "    ExportToDF(df_TrueNoise_anomalous_SNR30, IdentifyingInfo, SI_noise )\n",
    "    \n",
    "    # export the important params\n",
    "    Parameters = np.array([fastfracs[j]/norm,medfracs[j]/norm,slowfracs[j]/norm, fastD[j], medD[j], slowD[j], gammas[0], gammas[1], gammas[2], fastFA[j], medFA[j], slowFA[j], nearest_FAs[0], nearest_FAs[1], nearest_FAs[2], fast_rot[0],fast_rot[1],fast_rot[2], med_rot[0],med_rot[1],med_rot[2], slow_rot[0],slow_rot[1],slow_rot[2]])\n",
    "    ExportToDF(df_TrueParams, IdentifyingInfo, Parameters)\n",
    "\n",
    "\n",
    "\n",
    "filename = 'Simulated_IVIM_Curves_' + time.strftime(\"%Y%m%d-%H%M\", time.localtime()) + '.xlsx'\n",
    "with pd.ExcelWriter(filename,mode='w') as writer:  \n",
    "    # the true input parameters \n",
    "    df_TrueParams.to_excel(writer,sheet_name='Parameters')\n",
    "    \n",
    "    ## for SNR=100\n",
    "    df_True.to_excel(writer,sheet_name='TrueData_SNR_100')  \n",
    "    df_TrueNoise.to_excel(writer,sheet_name='TrueNoise_SNR_100')  \n",
    "    df_AveragedNoise.to_excel(writer,sheet_name='AveragedNoise_SNR_100')\n",
    "    \n",
    "    df_True_anomalous.to_excel(writer,sheet_name='TrueData_anomalous_SNR_100')  \n",
    "    df_TrueNoise_anomalous.to_excel(writer,sheet_name='TrueNoise_anomalous_SNR_100')  \n",
    "    df_AveragedNoise_anomalous.to_excel(writer,sheet_name='AveragedNoise_anomalous_SNR_100')\n",
    "    \n",
    "    \n",
    "    # for SNR=50\n",
    "    df_True_SNR50.to_excel(writer,sheet_name='TrueData_SNR_50')  \n",
    "    df_TrueNoise_SNR50.to_excel(writer,sheet_name='TrueNoise_SNR_50')  \n",
    "    df_AveragedNoise_SNR50.to_excel(writer,sheet_name='AveragedNoise_SNR_50')\n",
    "    \n",
    "    df_True_anomalous_SNR50.to_excel(writer,sheet_name='TrueData_anomalous_SNR_50')  \n",
    "    df_TrueNoise_anomalous_SNR50.to_excel(writer,sheet_name='TrueNoise_anomalous_SNR_50')  \n",
    "    df_AveragedNoise_anomalous_SNR50.to_excel(writer,sheet_name='AveragedNoise_anomalous_SNR_50')\n",
    "    \n",
    "    \n",
    "    # for SNR=30\n",
    "    df_True_SNR30.to_excel(writer,sheet_name='TrueData_SNR_30')  \n",
    "    df_TrueNoise_SNR30.to_excel(writer,sheet_name='TrueNoise_SNR_30')  \n",
    "    df_AveragedNoise_SNR30.to_excel(writer,sheet_name='AveragedNoise_SNR_30')\n",
    "    \n",
    "    df_True_anomalous_SNR30.to_excel(writer,sheet_name='TrueData_anomalous_SNR_30')  \n",
    "    df_TrueNoise_anomalous_SNR30.to_excel(writer,sheet_name='TrueNoise_anomalous_SNR_30')  \n",
    "    df_AveragedNoise_anomalous_SNR30.to_excel(writer,sheet_name='AveragedNoise_anomalous_SNR_30')\n",
    "    \n",
    "#writer.close()\n",
    "elapsed = time.time() - t\n",
    "print('Completed in ', elapsed)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c6253",
   "metadata": {},
   "source": [
    "# now run and save fits using MATLAB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "919fb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.cd(r'/Users/miraliu/Desktop/PostDocCode/IVIM_Fitting_Methods', nargout=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "524d7157",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m## now using Matlab code for Algorithm1\u001b[39;00m\n\u001b[1;32m     31\u001b[0m struct \u001b[38;5;241m=\u001b[39m eng\u001b[38;5;241m.\u001b[39mAlgorithm1(b_values,df_AveragedNoise\u001b[38;5;241m.\u001b[39miloc[j,\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m))\n\u001b[0;32m---> 32\u001b[0m [D, Dstar, f, SSE, rsq, adj_rsq]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(struct\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     33\u001b[0m Export_fits \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m*\u001b[39mD, \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mDstar, f, SSE, rsq, adj_rsq]\n\u001b[1;32m     34\u001b[0m ExportToDF(df_Algorithm1, IdentifyingInfo, Export_fits)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "filename = 'Simulated_IVIM_Curves_20250202-1921.xlsx'\n",
    "fileloc = '/Users/miraliu/Desktop/PostDocCode/IVIM_Fitting_Methods/' + filename\n",
    "\n",
    "df_TrueParams = pd.read_excel(fileloc,sheet_name = 'Parameters') \n",
    "df_TrueParams=df_TrueParams.rename(columns={c: 'true '+c for c in df_TrueParams.columns if c not in ['Run Number', 'Unnamed']})\n",
    "df_TrueParams=df_TrueParams.rename(columns={c: c+'tion' for c in df_TrueParams.columns if 'frac' in c})\n",
    "\n",
    "# AN_A_SNR_50 = averaged with noise (AN) Anomalous (A), with SNR=100\n",
    "df_AveragedNoise = pd.read_excel(fileloc,sheet_name = 'AveragedNoise_anomalous_SNR_100') \n",
    "df_AveragedNoise = df_AveragedNoise.fillna(0)\n",
    "\n",
    "\n",
    "b_values=np.array([0,50,100,150,200,250,300,500,700,900])\n",
    "\n",
    "# trying bi-exp fit to the df_True\n",
    "TrueFracs = []\n",
    "TrueDiffs = []\n",
    "TrueGammas = []\n",
    "FitFracs = []\n",
    "FitDiffs = []\n",
    "r2_fit = []\n",
    "\n",
    "df_Algorithm1 = pd.DataFrame(columns=['Run Number', 'D', 'Dstar','f', 'SSE', 'rsq', 'adj rsq'])\n",
    "df_Algorithm2 = pd.DataFrame(columns=['Run Number', 'D', 'Dstar','f', 'SSE', 'rsq', 'adj rsq'])\n",
    "df_Algorithm3 = pd.DataFrame(columns=['Run Number', 'D', 'Dstar','f', 'SSE', 'rsq', 'adj rsq'])\n",
    "df_Algorithm4 = pd.DataFrame(columns=['Run Number', 'D', 'Dstar','f', 'SSE', 'rsq', 'adj rsq'])\n",
    "\n",
    "for j in range(10):\n",
    "    IdentifyingInfo = 'Run Number ' + str(j)\n",
    "    ## now using Matlab code for Algorithm1\n",
    "    struct = eng.Algorithm1(b_values,df_AveragedNoise.iloc[j,2:].to_numpy().astype(float))\n",
    "    [D, Dstar, f, SSE, rsq, adj_rsq]=list(struct.values())\n",
    "    Export_fits = [1000*D, 100*Dstar, f, SSE, rsq, adj_rsq]\n",
    "    ExportToDF(df_Algorithm1, IdentifyingInfo, Export_fits)\n",
    "    \n",
    "    ## now using Matlab code for Algorithm2\n",
    "    struct = eng.Algorithm2(b_values,df_AveragedNoise.iloc[j,2:].to_numpy().astype(float))\n",
    "    [D, Dstar, f, SSE, rsq, adj_rsq]=list(struct.values())\n",
    "    Export_fits = [1000*D, 100*Dstar, f, SSE, rsq, adj_rsq]\n",
    "    ExportToDF(df_Algorithm2, IdentifyingInfo, Export_fits)\n",
    "    \n",
    "    ## now using Matlab code for Algorithm3\n",
    "    struct = eng.Algorithm3(b_values,df_AveragedNoise.iloc[j,2:].to_numpy().astype(float))\n",
    "    [D, Dstar, f, SSE, rsq, adj_rsq]=list(struct.values())\n",
    "    Export_fits = [1000*D, 100*Dstar, f, SSE, rsq, adj_rsq]\n",
    "    ExportToDF(df_Algorithm3, IdentifyingInfo, Export_fits)\n",
    "    \n",
    "    ## now using Matlab code for Algorithm4\n",
    "    struct = eng.Algorithm4(b_values,df_AveragedNoise.iloc[j,2:].to_numpy().astype(float))\n",
    "    [D, Dstar, f, SSE, rsq, adj_rsq]=list(struct.values())\n",
    "    Export_fits = [1000*D, 100*Dstar, f, SSE, rsq, adj_rsq]\n",
    "    ExportToDF(df_Algorithm4, IdentifyingInfo, Export_fits)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59cc8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Fit_Simulated_IVIM_Curves_20250202-1921.xlsx'\n",
    "with pd.ExcelWriter(filename,mode='w') as writer:  \n",
    "    df_Algorithm1.to_excel(writer,sheet_name='Algorithm1') \n",
    "with pd.ExcelWriter(filename,mode='a') as writer:  \n",
    "    df_Algorithm2.to_excel(writer,sheet_name='Algorithm2') \n",
    "    df_Algorithm3.to_excel(writer,sheet_name='Algorithm3') \n",
    "    df_Algorithm4.to_excel(writer,sheet_name='Algorithm4') \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## order given true values from fast to slow just in case\n",
    "    givengammas = np.array([df_TrueParams['true fast gamma'].iloc[j],df_TrueParams['true slow gamma'].iloc[j]])\n",
    "    givenfracs = np.array([df_TrueParams['true fast fraction'].iloc[j],df_TrueParams['true slow fraction'].iloc[j]])\n",
    "    givendiffusions = np.array([df_TrueParams['true fast diffusion'].iloc[j],df_TrueParams['true slow diffusion'].iloc[j]])\n",
    "    idx_sort = givendiffusions.argsort()\n",
    "    givenfracs = givenfracs[idx_sort[::-1]]\n",
    "    givendiffusions = givendiffusions[idx_sort[::-1]]\n",
    "\n",
    "    TrueFracs.append(list(givenfracs))\n",
    "    TrueDiffs.append(list(givendiffusions))\n",
    "    FitFracs.append(list(fracs))\n",
    "    FitDiffs.append(list(diffusions))\n",
    "    TrueGammas.append(list(givengammas))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4525113",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "print(f'goodness of fit: r2={np.mean(r2_fit):.5f}±{np.std(r2_fit):.5f}') \n",
    "TruefastfDs= 1000*np.array(TrueFracs)[:,0]*((np.array(TrueDiffs)[:,0]))\n",
    "FitfastfDs = 1000*np.array(FitFracs)[:,0]*np.array(FitDiffs)[:,0]\n",
    "\n",
    "TrueslowfDs= 1000*np.array(TrueFracs)[:,1]*(np.array(TrueDiffs)[:,1])\n",
    "FitslowfDs = 1000*np.array(FitFracs)[:,1]*np.array(FitDiffs)[:,1]\n",
    "\n",
    "\n",
    "\n",
    "AllTruefD = np.array(list(TruefastfDs)+list(TrueslowfDs))\n",
    "allFitfD = np.array(list(FitfastfDs)+list(FitslowfDs))\n",
    "\n",
    "pl.scatter(TruefastfDs, FitfastfDs,label= 'fast frac')\n",
    "pl.scatter(TrueslowfDs, FitslowfDs,label= 'slow frac')\n",
    "\n",
    "x = np.linspace(0,20,100)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(AllTruefD,allFitfD)\n",
    "r_value2 = r_value**2\n",
    "pl.plot(x,func(x,slope,intercept),label = f'y= {slope:.2f}x +{intercept: .1f}, $R^2$={r_value2:.2f}',color = 'grey') \n",
    "pl.legend()\n",
    "pl.title('biexponential fit')\n",
    "pl.show()\n",
    "\n",
    "\n",
    "pl.scatter(AllTruefD, allFitfD, s=1)\n",
    "x = np.linspace(0,25,100)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(AllTruefD,allFitfD)\n",
    "r_value2 = r_value**2\n",
    "pl.plot(x,func(x,slope,intercept),label = f'y= {slope:.2f}x +{intercept: .1f}, $R^2$={r_value2:.2f}',color = 'grey') \n",
    "pl.legend()\n",
    "pl.title('Bi-exponential')\n",
    "pl.xlabel('Input $f_AD_A$')\n",
    "pl.ylabel('Output Fit $fD$')\n",
    "pl.xlim(-0.3,25)\n",
    "pl.ylim(-0.3,25)\n",
    "pl.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('relative percent difference')\n",
    "print(f'fast fD  {200*np.median((FitfastfDs-TruefastfDs)/(TruefastfDs +FitfastfDs )):.5f}%')\n",
    "print(f'med fD {200*np.median((FitmedfDs-TruemedfDs)/(TruemedfDs + FitmedfDs)):.5f}%')\n",
    "print(f'slow fD {200*np.median((FitslowfDs-TrueslowfDs)/(TrueslowfDs + FitslowfDs)):.5f}%')\n",
    "\n",
    "print('\\nrelative abs percent difference')\n",
    "print(f'fast fD  {200*np.median(abs(FitfastfDs-TruefastfDs)/(TruefastfDs +FitfastfDs )):.5f}%')\n",
    "print(f'med fD {200*np.median(abs(FitmedfDs-TruemedfDs)/(TruemedfDs + FitmedfDs)):.5f}%')\n",
    "print(f'slow fD {200*np.median(abs(FitslowfDs-TrueslowfDs)/(TrueslowfDs + FitslowfDs)):.5f}%')\n",
    "\n",
    "\n",
    "print('\\npercent bland altman')\n",
    "blandalt_calc(FitfastfDs,TruefastfDs,'fast fD')\n",
    "blandalt_calc(FitmedfDs,TruemedfDs,'med fD')\n",
    "blandalt_calc(FitslowfDs,TrueslowfDs,'slow fD')\n",
    "blandalt_calc(allFitfD,AllTruefD,'all fD')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('individual f and D')\n",
    "\n",
    "\n",
    "\n",
    "TruefastfDs= np.array(TrueFracs)[:,0]\n",
    "FitfastfDs = np.array(FitFracs)[:,0]\n",
    "\n",
    "TrueslowfDs= np.array(TrueFracs)[:,1]\n",
    "FitslowfDs = np.array(FitFracs)[:,1]\n",
    "\n",
    "\n",
    "\n",
    "AllTruefD = np.array(list(TruefastfDs)+list(TrueslowfDs))\n",
    "allFitfD = np.array(list(FitfastfDs)+list(FitslowfDs))\n",
    "\n",
    "\n",
    "x = np.linspace(0,1,100)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(AllTruefD,allFitfD)\n",
    "pl.scatter(AllTruefD,allFitfD)\n",
    "r_value2 = r_value**2\n",
    "pl.plot(x,func(x,slope,intercept),label = f'y= {slope:.2f}x +{intercept: .1f}, $R^2$={r_value2:.2f}',color = 'grey') \n",
    "pl.legend()\n",
    "pl.title('biexponential fit f')\n",
    "pl.show()\n",
    "print('relative percent difference')\n",
    "print(f'fast f  {200*np.median((FitfastfDs-TruefastfDs)/(TruefastfDs +FitfastfDs )):.5f}%')\n",
    "print(f'med f {200*np.median((FitmedfDs-TruemedfDs)/(TruemedfDs + FitmedfDs)):.5f}%')\n",
    "print(f'slow f {200*np.median((FitslowfDs-TrueslowfDs)/(TrueslowfDs + FitslowfDs)):.5f}%')\n",
    "\n",
    "\n",
    "\n",
    "print('\\nrelative abs percent difference')\n",
    "print(f'fast f  {200*np.median(abs(FitfastfDs-TruefastfDs)/(TruefastfDs +FitfastfDs )):.5f}%')\n",
    "print(f'med f {200*np.median(abs(FitmedfDs-TruemedfDs)/(TruemedfDs + FitmedfDs)):.5f}%')\n",
    "print(f'slow f {200*np.median(abs(FitslowfDs-TrueslowfDs)/(TrueslowfDs + FitslowfDs)):.5f}%')\n",
    "\n",
    "\n",
    "print('\\npercent bland altman')\n",
    "blandalt_calc(FitfastfDs,TruefastfDs,'fast f')\n",
    "blandalt_calc(FitmedfDs,TruemedfDs,'med f')\n",
    "blandalt_calc(FitslowfDs,TrueslowfDs,'slow f')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TruefastfDs= 1000*(np.array(TrueDiffs)[:,0])\n",
    "FitfastfDs = 1000*np.array(FitDiffs)[:,0]\n",
    "\n",
    "TrueslowfDs= 1000*(np.array(TrueDiffs)[:,1])\n",
    "FitslowfDs = 1000*np.array(FitDiffs)[:,1]\n",
    "\n",
    "\n",
    "AllTruefD = np.array(list(TruefastfDs)+list(TrueslowfDs))\n",
    "allFitfD = np.array(list(FitfastfDs)+list(FitslowfDs))\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(0,100,100)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(AllTruefD,allFitfD)\n",
    "pl.scatter(AllTruefD,allFitfD)\n",
    "r_value2 = r_value**2\n",
    "pl.plot(x,func(x,slope,intercept),label = f'y= {slope:.2f}x +{intercept: .1f}, $R^2$={r_value2:.2f}',color = 'grey') \n",
    "pl.legend()\n",
    "pl.title('biexponential fit D')\n",
    "pl.show()\n",
    "print('relative percent difference')\n",
    "print(f'fast D  {200*np.median((FitfastfDs-TruefastfDs)/(TruefastfDs +FitfastfDs )):.5f}%')\n",
    "print(f'med D {200*np.median((FitmedfDs-TruemedfDs)/(TruemedfDs + FitmedfDs)):.5f}%')\n",
    "print(f'slow D {200*np.median((FitslowfDs-TrueslowfDs)/(TrueslowfDs + FitslowfDs)):.5f}%')\n",
    "\n",
    "\n",
    "print('\\nrelative abs percent difference')\n",
    "print(f'fast D  {200*np.median(abs(FitfastfDs-TruefastfDs)/(TruefastfDs +FitfastfDs )):.5f}%')\n",
    "print(f'med D {200*np.median(abs(FitmedfDs-TruemedfDs)/(TruemedfDs + FitmedfDs)):.5f}%')\n",
    "print(f'slow D {200*np.median(abs(FitslowfDs-TrueslowfDs)/(TrueslowfDs + FitslowfDs)):.5f}%')\n",
    "\n",
    "\n",
    "print('\\npercent bland altman')\n",
    "blandalt_calc(FitfastfDs,TruefastfDs,'fast D')\n",
    "blandalt_calc(FitmedfDs,TruemedfDs,'med D')\n",
    "blandalt_calc(FitslowfDs,TrueslowfDs,'slow D')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
